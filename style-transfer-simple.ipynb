{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 316,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83
        },
        "id": "NIxH20o2eFoc",
        "outputId": "4785bcbb-4070-4e68-c2b5-4a1dfdccbad2"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing.image import load_img, save_img, img_to_array\n",
        "import numpy as np\n",
        "from scipy.optimize import fmin_l_bfgs_b\n",
        "import time\n",
        "\n",
        "from keras.applications import vgg19\n",
        "from keras import backend as K\n",
        "from pathlib import Path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 317,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Habilita compatiblidad hacia atrás\n",
        "import tensorflow._api.v2.compat.v1 as tf\n",
        "tf.compat.v1.disable_eager_execution()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 318,
      "metadata": {
        "id": "iLkV1bnFl_tK"
      },
      "outputs": [],
      "source": [
        "# Base\n",
        "base_image_path = Path.cwd() / Path(\"content-propio/Toto_small.jpg\")\n",
        "# base_image_path = Path.cwd() / Path(\"content-propio/guitar_small.jpg\")\n",
        "# base_image_path = Path.cwd() / Path(\"content-propio/facultad_small.jpg\")\n",
        "# base_image_path = Path.cwd() / Path(\"content-propio/fondo_small.jpg\")\n",
        "base_image_path = Path.cwd() / Path(\"content-propio/story_small.jpg\")\n",
        "# base_image_path = Path.cwd() / Path(\"content-propio/achiras_pelota_small.jpg\")\n",
        "# base_image_path = Path.cwd() / Path(\"content/775px-Neckarfront_Tübingen_Mai_2017.jpg\")\n",
        "\n",
        "# Style\n",
        "# style_reference_image_path = Path.cwd() / Path(\"content/La_noche_estrellada1.jpg\")\n",
        "# style_reference_image_path = Path.cwd() / Path(\"content-propio/nieve_small.jpg\")\n",
        "style_reference_image_path = Path.cwd() / Path(\"content-propio/cubism.png\")\n",
        "# style_reference_image_path = Path.cwd() / Path(\"content-propio/kandinsky_small.jpg\")\n",
        "\n",
        "result_prefix = Path.cwd() / Path(\"content-propio/output\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 319,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Definimos el tamaño de las imágenes a utilizar (fija el tamaño de salida)\n",
        "# width, height = load_img(base_image_path).size\n",
        "# img_nrows = 400\n",
        "# img_ncols = int(width * img_nrows / height)\n",
        "# print(img_nrows, img_ncols)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 320,
      "metadata": {
        "id": "P9Dt3aaEmJWS"
      },
      "outputs": [],
      "source": [
        "# hiperparámetros\n",
        "\n",
        "total_variation_weight = 0.01\n",
        "# total_variation_weight = 0.5\n",
        "# total_variation_weight = 0.1\n",
        "\n",
        "# style_weight = 1000\n",
        "# style_weight = 5\n",
        "# style_weight = 50\n",
        "# style_weight = 1\n",
        "style_weight = 10\n",
        "\n",
        "content_weight = 1\n",
        "# content_weight = 10\n",
        "# content_weight = 100\n",
        "\n",
        "# iterations = 100\n",
        "# iterations = 300\n",
        "# iterations = 3\n",
        "iterations = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 321,
      "metadata": {
        "id": "CQQJOhCVuse6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "497 700\n"
          ]
        }
      ],
      "source": [
        "# Definimos el tamaño de las imágenes a utilizar (se conserva tamaño original)\n",
        "width, height = load_img(base_image_path).size\n",
        "img_nrows = height\n",
        "img_ncols = width\n",
        "print(img_nrows, img_ncols)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 322,
      "metadata": {
        "id": "tAkljg4zuzYd"
      },
      "outputs": [],
      "source": [
        "def preprocess_image(image_path):\n",
        "    img = load_img(image_path, target_size=(img_nrows, img_ncols))\n",
        "    img = img_to_array(img)\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "    img = vgg19.preprocess_input(img)\n",
        "    return img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 323,
      "metadata": {
        "id": "y5LaTrsAu14z"
      },
      "outputs": [],
      "source": [
        "def deprocess_image(x):\n",
        "    x = x.reshape((img_nrows, img_ncols, 3))\n",
        "    # Remove zero-center by mean pixel\n",
        "    x[:, :, 0] += 103.939\n",
        "    x[:, :, 1] += 116.779\n",
        "    x[:, :, 2] += 123.68\n",
        "    # 'BGR'->'RGB'\n",
        "    x = x[:, :, ::-1]\n",
        "    x = np.clip(x, 0, 255).astype('uint8')\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 324,
      "metadata": {
        "id": "HYNio09mu4S3"
      },
      "outputs": [],
      "source": [
        "# get tensor representations of our images\n",
        "# K.variable convierte un numpy array en un tensor, para \n",
        "base_image = K.variable(preprocess_image(base_image_path))\n",
        "style_reference_image = K.variable(preprocess_image(style_reference_image_path))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 325,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "a1Lbw02Uu--o",
        "outputId": "6cc926fa-55af-43fa-fe91-3b68c0910502"
      },
      "outputs": [],
      "source": [
        "combination_image = K.placeholder((1, img_nrows, img_ncols, 3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 326,
      "metadata": {
        "id": "gGO_jGFfvEbF"
      },
      "outputs": [],
      "source": [
        "# combine the 3 images into a single Keras tensor\n",
        "input_tensor = K.concatenate([base_image,\n",
        "                              style_reference_image,\n",
        "                              combination_image], axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 327,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "tdG59VRavHGB",
        "outputId": "a133befb-68d1-4c51-99e6-417c1103f726"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-08-28 17:41:14.549645: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
            "2023-08-28 17:41:14.597501: W tensorflow/c/c_api.cc:304] Operation '{name:'block2_conv1_13/kernel/Assign' id:16447 op device:{requested: '', assigned: ''} def:{{{node block2_conv1_13/kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](block2_conv1_13/kernel, block2_conv1_13/kernel/Initializer/stateless_random_uniform)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
            "2023-08-28 17:41:14.792799: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model loaded.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-08-28 17:41:15.148527: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
          ]
        }
      ],
      "source": [
        "# build the VGG19 network with our 3 images as input\n",
        "# the model will be loaded with pre-trained ImageNet weights\n",
        "model = vgg19.VGG19(input_tensor=input_tensor,\n",
        "                    weights='imagenet', include_top=False)\n",
        "print('Model loaded.')\n",
        "\n",
        "# get the symbolic outputs of each \"key\" layer (we gave them unique names).\n",
        "outputs_dict = dict([(layer.name, layer.output) for layer in model.layers])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 328,
      "metadata": {
        "id": "K1FODPATvJ1k"
      },
      "outputs": [],
      "source": [
        "def gram_matrix(x):\n",
        "    features = K.batch_flatten(K.permute_dimensions(x, (2, 0, 1)))\n",
        "    gram = K.dot(features, K.transpose(features))\n",
        "    return gram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 329,
      "metadata": {
        "id": "1-Gt0ahWvN6q"
      },
      "outputs": [],
      "source": [
        "def style_loss(style, combination):\n",
        "    assert K.ndim(style) == 3\n",
        "    assert K.ndim(combination) == 3\n",
        "    S = gram_matrix(style)\n",
        "    C = gram_matrix(combination)\n",
        "    channels = 3\n",
        "    size = img_nrows * img_ncols\n",
        "    return K.sum(K.square(S - C)) / (4.0 * (channels ** 2) * (size ** 2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 330,
      "metadata": {
        "id": "XCqnju5RvQCo"
      },
      "outputs": [],
      "source": [
        "def content_loss(base, combination):\n",
        "    return K.sum(K.square(combination - base))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 331,
      "metadata": {
        "id": "udEp5h31vRnY"
      },
      "outputs": [],
      "source": [
        "# Se define el 1.25 como constante (hyperparámetro)\n",
        "def total_variation_loss(x):\n",
        "    assert K.ndim(x) == 4\n",
        "    a = K.square(\n",
        "        x[:, :img_nrows - 1, :img_ncols - 1, :] - x[:, 1:, :img_ncols - 1, :])\n",
        "    b = K.square(\n",
        "        x[:, :img_nrows - 1, :img_ncols - 1, :] - x[:, :img_nrows - 1, 1:, :])\n",
        "    return K.sum(K.pow(a + b, 1.25))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 332,
      "metadata": {
        "id": "-65vcinbvTZ0"
      },
      "outputs": [],
      "source": [
        "REF_BASE_IMG = 0\n",
        "REF_STYLE_IMG = 1\n",
        "REF_COMB_IMG = 2\n",
        "\n",
        "# Armamos la loss total\n",
        "loss = K.variable(0.0)\n",
        "\n",
        "layer_features = outputs_dict['block5_conv2']\n",
        "\n",
        "base_image_features = layer_features[REF_BASE_IMG, :, :, :]\n",
        "combination_features = layer_features[REF_COMB_IMG, :, :, :]\n",
        "\n",
        "loss = loss + content_weight * content_loss(base_image_features,combination_features)\n",
        "\n",
        "feature_layers = ['block1_conv1', 'block2_conv1',\n",
        "                  'block3_conv1', 'block4_conv1',\n",
        "                  'block5_conv1']\n",
        "\n",
        "for layer_name in feature_layers:\n",
        "    layer_features = outputs_dict[layer_name]\n",
        "    style_reference_features = layer_features[REF_STYLE_IMG, :, :, :] \n",
        "    combination_features = layer_features[REF_COMB_IMG, :, :, :]\n",
        "    \n",
        "    sl = style_loss(style_reference_features, combination_features)\n",
        "    loss = loss + (style_weight / len(feature_layers)) * sl\n",
        "\n",
        "loss = loss + total_variation_weight * total_variation_loss(combination_image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 333,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "id": "pbz4n1OhvV2K",
        "outputId": "c2b208c6-7ddd-4a40-eeda-525f0809b963"
      },
      "outputs": [],
      "source": [
        "grads = K.gradients(loss, combination_image)\n",
        "\n",
        "outputs = [loss]\n",
        "if isinstance(grads, (list, tuple)):\n",
        "    outputs += grads\n",
        "else:\n",
        "    outputs.append(grads)\n",
        "\n",
        "f_outputs = K.function([combination_image], outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 334,
      "metadata": {
        "id": "zVE1_qemvZeN"
      },
      "outputs": [],
      "source": [
        "def eval_loss_and_grads(x):\n",
        "    # Reshape the input image to match the expected input shape for the model\n",
        "    x = x.reshape((1, img_nrows, img_ncols, 3))\n",
        "    # Compute the loss and gradients for the input image\n",
        "    outs = f_outputs([x])\n",
        "    # Extract the loss value from the computed outputs\n",
        "    loss_value = outs[0]\n",
        "    # If there is only one gradient value, flatten it and convert to float64\n",
        "    if len(outs[1:]) == 1:\n",
        "        grad_values = outs[1].flatten().astype('float64')\n",
        "    # If there are multiple gradient values, convert them to a flat numpy array of float64\n",
        "    else:\n",
        "        grad_values = np.array(outs[1:]).flatten().astype('float64')\n",
        "    # Return the computed loss and gradient values\n",
        "    return loss_value, grad_values\n",
        "\n",
        "# this Evaluator class makes it possible\n",
        "# to compute loss and gradients in one pass\n",
        "# while retrieving them via two separate functions,\n",
        "# \"loss\" and \"grads\". This is done because scipy.optimize\n",
        "# requires separate functions for loss and gradients,\n",
        "# but computing them separately would be inefficient."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 335,
      "metadata": {
        "id": "Qbl9roIgvdb1"
      },
      "outputs": [],
      "source": [
        "class Evaluator(object):\n",
        "\n",
        "    def __init__(self):\n",
        "        self.loss_value = None\n",
        "        self.grads_values = None\n",
        "\n",
        "    def loss(self, x):\n",
        "        assert self.loss_value is None\n",
        "        loss_value, grad_values = eval_loss_and_grads(x)\n",
        "        self.loss_value = loss_value\n",
        "        self.grad_values = grad_values\n",
        "        return self.loss_value\n",
        "\n",
        "    def grads(self, x):\n",
        "        assert self.loss_value is not None\n",
        "        grad_values = np.copy(self.grad_values)\n",
        "        self.loss_value = None\n",
        "        self.grad_values = None\n",
        "        return grad_values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 336,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ! mkdir -p content/output\n",
        "! mkdir -p content-propio/output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 337,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Content: story_small\n",
            "Style: cubism\n",
            "total_variation_weight: 0.01\n",
            "style_weight: 1\n",
            "content_weight: 100\n",
            "Iterations: 10\n"
          ]
        }
      ],
      "source": [
        "print(\"Content:\", base_image_path.name.split(\".\")[0])\n",
        "print(\"Style:\", style_reference_image_path.name.split(\".\")[0])\n",
        "print(\"total_variation_weight:\", total_variation_weight)\n",
        "print(\"style_weight:\", style_weight)\n",
        "print(\"content_weight:\", content_weight)\n",
        "print(\"Iterations:\", iterations)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 338,
      "metadata": {},
      "outputs": [],
      "source": [
        "BASEIMG = base_image_path.name.upper().split(\".\")[0]\n",
        "STYLEIMG = style_reference_image_path.name.upper().split(\".\")[0]\n",
        "TOTALVARIATIONW = str(total_variation_weight)\n",
        "STYLEW = str(style_weight)\n",
        "CONTENTW = str(content_weight)\n",
        "IT_NUMBER = str(1)\n",
        "# print(f'output_{BASEIMG}_{STYLEIMG}_{TOTALVARIATIONW}_{STYLEW}_{CONTENTW}_at_iteration_{IT_NUMBER}.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 339,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "n31YBwCVvhAI",
        "outputId": "4c1bf03c-9d66-48ea-93f2-4489fc20beaa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start of iteration 0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-08-28 17:41:16.749769: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
            "2023-08-28 17:41:16.782121: W tensorflow/c/c_api.cc:304] Operation '{name:'Variable_41/Assign' id:16909 op device:{requested: '', assigned: ''} def:{{{node Variable_41/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](Variable_41, Variable_41/Initializer/initial_value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
            "2023-08-28 17:41:16.980612: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
            "2023-08-28 17:41:17.060349: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current loss value: 7060884500.0\n",
            "Image saved as /Users/hordia/dev/ML/course-ITBA-DL/course-notebooks-labs/TP-Final-Computer-Vision/hordia-Trabajo-Final-CV/content-propio/output/output_STORY_SMALL_CUBISM_0.01_1_100_at_iteration_0.png\n",
            "Iteration 0 completed in 13s\n",
            "Start of iteration 1\n",
            "Current loss value: 6069878300.0\n",
            "Image saved as /Users/hordia/dev/ML/course-ITBA-DL/course-notebooks-labs/TP-Final-Computer-Vision/hordia-Trabajo-Final-CV/content-propio/output/output_STORY_SMALL_CUBISM_0.01_1_100_at_iteration_1.png\n",
            "Iteration 1 completed in 11s\n",
            "Start of iteration 2\n",
            "Current loss value: 5209514500.0\n",
            "Image saved as /Users/hordia/dev/ML/course-ITBA-DL/course-notebooks-labs/TP-Final-Computer-Vision/hordia-Trabajo-Final-CV/content-propio/output/output_STORY_SMALL_CUBISM_0.01_1_100_at_iteration_2.png\n",
            "Iteration 2 completed in 11s\n",
            "Start of iteration 3\n",
            "Current loss value: 4530601000.0\n",
            "Image saved as /Users/hordia/dev/ML/course-ITBA-DL/course-notebooks-labs/TP-Final-Computer-Vision/hordia-Trabajo-Final-CV/content-propio/output/output_STORY_SMALL_CUBISM_0.01_1_100_at_iteration_3.png\n",
            "Iteration 3 completed in 11s\n",
            "Start of iteration 4\n",
            "Current loss value: 4035812600.0\n",
            "Image saved as /Users/hordia/dev/ML/course-ITBA-DL/course-notebooks-labs/TP-Final-Computer-Vision/hordia-Trabajo-Final-CV/content-propio/output/output_STORY_SMALL_CUBISM_0.01_1_100_at_iteration_4.png\n",
            "Iteration 4 completed in 11s\n",
            "Start of iteration 5\n",
            "Current loss value: 3661424400.0\n",
            "Image saved as /Users/hordia/dev/ML/course-ITBA-DL/course-notebooks-labs/TP-Final-Computer-Vision/hordia-Trabajo-Final-CV/content-propio/output/output_STORY_SMALL_CUBISM_0.01_1_100_at_iteration_5.png\n",
            "Iteration 5 completed in 11s\n",
            "Start of iteration 6\n",
            "Current loss value: 3383116800.0\n",
            "Image saved as /Users/hordia/dev/ML/course-ITBA-DL/course-notebooks-labs/TP-Final-Computer-Vision/hordia-Trabajo-Final-CV/content-propio/output/output_STORY_SMALL_CUBISM_0.01_1_100_at_iteration_6.png\n",
            "Iteration 6 completed in 11s\n",
            "Start of iteration 7\n",
            "Current loss value: 3143312100.0\n",
            "Image saved as /Users/hordia/dev/ML/course-ITBA-DL/course-notebooks-labs/TP-Final-Computer-Vision/hordia-Trabajo-Final-CV/content-propio/output/output_STORY_SMALL_CUBISM_0.01_1_100_at_iteration_7.png\n",
            "Iteration 7 completed in 11s\n",
            "Start of iteration 8\n",
            "Current loss value: 2956649000.0\n",
            "Image saved as /Users/hordia/dev/ML/course-ITBA-DL/course-notebooks-labs/TP-Final-Computer-Vision/hordia-Trabajo-Final-CV/content-propio/output/output_STORY_SMALL_CUBISM_0.01_1_100_at_iteration_8.png\n",
            "Iteration 8 completed in 11s\n",
            "Start of iteration 9\n",
            "Current loss value: 2789632000.0\n",
            "Image saved as /Users/hordia/dev/ML/course-ITBA-DL/course-notebooks-labs/TP-Final-Computer-Vision/hordia-Trabajo-Final-CV/content-propio/output/output_STORY_SMALL_CUBISM_0.01_1_100_at_iteration_9.png\n",
            "Iteration 9 completed in 11s\n"
          ]
        }
      ],
      "source": [
        "evaluator = Evaluator() # \n",
        "\n",
        "# run scipy-based optimization (L-BFGS) over the pixels of the generated image\n",
        "# so as to minimize the neural style loss\n",
        "x = preprocess_image(base_image_path)\n",
        "\n",
        "for i in range(iterations):\n",
        "    print('Start of iteration', i)\n",
        "    start_time = time.time()\n",
        "    x, min_val, info = fmin_l_bfgs_b(evaluator.loss, x.flatten(),\n",
        "                                     fprime=evaluator.grads, maxfun=20)\n",
        "    print('Current loss value:', min_val)\n",
        "    # save current generated image\n",
        "    img = deprocess_image(x.copy())\n",
        "    # fname = result_prefix / ('output_at_iteration_%d.png' % i)\n",
        "    fname = result_prefix / (f'output_{BASEIMG}_{STYLEIMG}_{TOTALVARIATIONW}_{STYLEW}_{CONTENTW}_at_iteration_{i}.png')\n",
        "    save_img(fname, img)\n",
        "    end_time = time.time()\n",
        "    print('Image saved as', fname)\n",
        "    print('Iteration %d completed in %ds' % (i, end_time - start_time))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<center>\n",
        "\n",
        "| Content | Style |\n",
        "| --- | --- |\n",
        "| <img src='./content-propio/achiras_pelota_small.jpg'> | <img src='./content/La_noche_estrellada1.jpg'> |\n",
        "\n",
        "\n",
        "| total_variation_weight | style_weight | content_weight | interations |\n",
        "| --- | --- | --- | --- |\n",
        "| 0.01 | 5 | 1 | 100 |\n",
        "\n",
        "\n",
        "<img src='./resultados/PUNTO-9/output_PELOTA_NOCHE-ESTRELLADA_0.01_5_1_iteration_99.png'>\n",
        "\n",
        "</center>\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Trabajo Final CNN - Style Transfer.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
