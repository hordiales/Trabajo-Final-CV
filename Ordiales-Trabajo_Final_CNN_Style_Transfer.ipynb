{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "qCY6UbkkI9_N"
      },
      "source": [
        "# Style Transfer\n",
        "\n",
        "\n",
        "<img src=\"https://i0.wp.com/chelseatroy.com/wp-content/uploads/2018/12/neural_style_transfer.png?resize=768%2C311&ssl=1\">\n",
        "\n",
        "\n",
        "La idea de este trabajo final es reproducir el siguiente paper:\n",
        "\n",
        "https://arxiv.org/pdf/1508.06576.pdf\n",
        "\n",
        "El objetivo es transferir el estilo de una imagen dada a otra imagen distinta. \n",
        "\n",
        "Como hemos visto en clase, las primeras capas de una red convolucional se activan ante la presencia de ciertos patrones vinculados a detalles muy pequeños.\n",
        "\n",
        "A medida que avanzamos en las distintas capas de una red neuronal convolucional, los filtros se van activando a medida que detectan patrones de formas cada vez mas complejos.\n",
        "\n",
        "Lo que propone este paper es asignarle a la activación de las primeras capas de una red neuronal convolucional (por ejemplo VGG19) la definición del estilo y a la activación de las últimas capas de la red neuronal convolucional, la definición del contenido.\n",
        "\n",
        "La idea de este paper es, a partir de dos imágenes (una que aporte el estilo y otra que aporte el contenido) analizar cómo es la activación de las primeras capas para la imagen que aporta el estilo y cómo es la activación de las últimas capas de la red convolucional para la imagen que aporta el contenido. A partir de esto se intentará sintetizar una imagen que active los filtros de las primeras capas que se activaron con la imagen que aporta el estilo y los filtros de las últimas capas que se activaron con la imagen que aporta el contenido.\n",
        "\n",
        "A este procedimiento se lo denomina neural style transfer.\n",
        "\n",
        "En este trabajo se deberá leer el paper mencionado y en base a ello, entender la implementación que se muestra a continuación y contestar preguntas sobre la misma.\n",
        "\n",
        "Una metodología posible es hacer una lectura rápida del paper (aunque esto signifique no entender algunos detalles del mismo) y luego ir analizando el código y respondiendo las preguntas. A medida que se planteen las preguntas, volviendo a leer secciones específicas del paper terminará de entender los detalles que pudieran haber quedado pendientes.\n",
        "\n",
        "Lo primero que haremos es cargar dos imágenes, una que aporte el estilo y otra que aporte el contenido. A tal fin utilizaremos imágenes disponibles en la web."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        },
        "id": "kyHsa2t0SxZi",
        "outputId": "e72fcf52-62ed-42f1-f64e-cdb05d049797"
      },
      "outputs": [],
      "source": [
        "# Creamos el directorio para los archivos de salida\n",
        "# !mkdir -p content/output\n",
        "\n",
        "# Imagen para estilo\n",
        "#!wget https://upload.wikimedia.org/wikipedia/commons/5/52/La_noche_estrellada1.jpg\n",
        "\n",
        "# Imagen para contenido\n",
        "#!wget https://upload.wikimedia.org/wikipedia/commons/thumb/f/f4/Neckarfront_T%C3%BCbingen_Mai_2017.jpg/775px-Neckarfront_T%C3%BCbingen_Mai_2017.jpg\n",
        "\n",
        "# !mv *.jpg content/\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83
        },
        "id": "NIxH20o2eFoc",
        "outputId": "4785bcbb-4070-4e68-c2b5-4a1dfdccbad2"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing.image import load_img, save_img, img_to_array\n",
        "import numpy as np\n",
        "from scipy.optimize import fmin_l_bfgs_b\n",
        "import time\n",
        "\n",
        "from keras.applications import vgg19\n",
        "from keras import backend as K\n",
        "from pathlib import Path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Habilita compatiblidad hacia atrás\n",
        "import tensorflow._api.v2.compat.v1 as tf\n",
        "tf.compat.v1.disable_eager_execution()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Python Platform: macOS-13.5.1-arm64-arm-64bit\n",
            "Tensor Flow Version: 2.13.0\n",
            "Keras Version: 2.13.1\n",
            "\n",
            "Python 3.10.12 | packaged by conda-forge | (main, Jun 23 2023, 22:41:52) [Clang 15.0.7 ]\n",
            "Pandas 2.0.3\n",
            "Scikit-Learn 1.3.0\n",
            "GPU is available\n"
          ]
        }
      ],
      "source": [
        "# Listo versiones de las librerias para futura referencia\n",
        "import sys\n",
        "\n",
        "import pandas as pd\n",
        "import sklearn as sk\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "import platform\n",
        "\n",
        "print(f\"Python Platform: {platform.platform()}\")\n",
        "print(f\"Tensor Flow Version: {tf.__version__}\")\n",
        "print(f\"Keras Version: {keras.__version__}\")\n",
        "print()\n",
        "print(f\"Python {sys.version}\")\n",
        "print(f\"Pandas {pd.__version__}\")\n",
        "print(f\"Scikit-Learn {sk.__version__}\")\n",
        "gpu = len(tf.config.list_physical_devices('GPU'))>0\n",
        "print(\"GPU is\", \"available\" if gpu else \"NOT AVAILABLE\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "iLkV1bnFl_tK"
      },
      "outputs": [],
      "source": [
        "# Definimos las imagenes que vamos a utilizar, y el directorio de salida\n",
        "\n",
        "base_image_path = Path.cwd() / Path(\"content/775px-Neckarfront_Tübingen_Mai_2017.jpg\")\n",
        "style_reference_image_path = Path.cwd() / Path(\"content/La_noche_estrellada1.jpg\")\n",
        "result_prefix = Path.cwd() / Path(\"content/output\")\n",
        "iterations = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'775px-Neckarfront_Tübingen_Mai_2017.jpg'"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "base_image_path.name"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Gz2PeGfpeYzj"
      },
      "source": [
        "# 1) En base a lo visto en el paper ¿Qué significan los parámetros definidos en la siguiente celda?\n",
        "\n",
        "*Respuesta:*\n",
        "\n",
        "En la página 12 del paper se especifica la siguiente ecuación de Loss que luego se busca minimizar, la misma tiene 2 términos, uno correspondiente a la Loss de contenido y otro a la Loss de estilo:\n",
        "\n",
        "    L_total(p,a,x) = α L_content(p,x) + β L_style(a,x)\n",
        "\n",
        "Donde 'α' es el factor de peso que se le asigna a la Loss contenido y 'β' a la de estilo.\n",
        "\n",
        "*Aclaración:* En esta implementación la variable (o hiperparámetro del modelo ) 'content_weight' se corresponde directamente con el 'α' de la ecuación ya que multiplica directamente a la Loss de contenido. Por otro lado, 'style_weight' no representa directamente el 'β' sino una parte, ya que en este caso el valor se divide por la cantidad de capas antes de multiplicarse por la Loss de estilo.\n",
        "total_variation_weight es el valor que luego multiplica el total_variation_loss() de la imagen generada, como se verá más adelante.\n",
        "Al no ser parámetros entrenables, asumimos que todos son hiperparámetros del modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "P9Dt3aaEmJWS"
      },
      "outputs": [],
      "source": [
        "total_variation_weight = 0.1\n",
        "style_weight = 10\n",
        "content_weight = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "CQQJOhCVuse6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "400 517\n"
          ]
        }
      ],
      "source": [
        "# Definimos el tamaño de las imágenes a utilizar\n",
        "width, height = load_img(base_image_path).size\n",
        "img_nrows = 400\n",
        "img_ncols = int(width * img_nrows / height)\n",
        "print(img_nrows, img_ncols)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(517, 400)\n"
          ]
        }
      ],
      "source": [
        "# funciones keras: from keras.preprocessing.image import load_img, save_img, img_to_array\n",
        "img = load_img(base_image_path, target_size=(img_nrows, img_ncols))\n",
        "print(img.size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(400, 517, 3)\n"
          ]
        }
      ],
      "source": [
        "img = img_to_array(img)\n",
        "print(img.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1, 400, 517, 3)\n"
          ]
        }
      ],
      "source": [
        "img = np.expand_dims(img, axis=0)\n",
        "print(img.shape)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "gg2ct-8agm1E"
      },
      "source": [
        "# 2) Explicar qué hace la siguiente celda. En especial las últimas dos líneas de la función antes del return. ¿Por qué? Ayuda: https://keras.io/applications/\n",
        "\n",
        "*Respuesta:* Es una función que se encarga de realizar todos los procesamientos que son necesarios para poder utilizar cualquier imagen con el modelo definido en esta notebook.\n",
        "\n",
        "    img = load_img(image_path, target_size=(img_nrows, img_ncols))\n",
        "    \n",
        "La primer línea, a partir de un path y nombre de archivo, carga la imagen en una variable \"img\" y la redimensiona según los valores filas y columnas especificados en la celda anterior (el tamaño de las imagenes a utilizar)\n",
        "    \n",
        "    img = img_to_array(img)\n",
        "\n",
        "Convierte la imagen objeto tipo PIL a un array numpy con el siguiente shape (400, 517, 3)\n",
        "\n",
        "    np.expand_dims(img, axis=0)\n",
        "    \n",
        "Agrega al principio del array una dimensión extra, esto es porque muchos modelos de Deep Learning (incluyendo el VGG19) esperan un batch de imagenes como entrada. Con esta línea, se crea efectivamente un batch de una sola línea. El shape queda (1, 400, 517, 3)\n",
        "\n",
        "    img = vgg19.preprocess_input(img)\n",
        "\n",
        "La última línea es una función de Keras y termina de adaptar el array imagen al modelo con los pesos pre-entrenados VGG19. Convierte de el estándar para imagenes a color RGB (rojo, verde y azul) al BGR (azul, verde, rojo). Esta diferencia tiene que ver con el orden en que algunas bibliotecas para procesamiento tratan las imagenes a color. Además de esto, se centran los valores con respecto a la media del dataset ImageNet de referencia, pero sin escalar los mismos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "tAkljg4zuzYd"
      },
      "outputs": [],
      "source": [
        "def preprocess_image(image_path):\n",
        "    img = load_img(image_path, target_size=(img_nrows, img_ncols))\n",
        "    img = img_to_array(img)\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "    img = vgg19.preprocess_input(img)\n",
        "    return img"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "KTf0YDSagt10"
      },
      "source": [
        "# 3) Habiendo comprendido lo que hace la celda anterior, explique de manera muy concisa qué hace la siguiente celda. ¿Qué relación tiene con la celda anterior?\n",
        "\n",
        "*Respuesta:*\n",
        "\n",
        "Es una función para realizar el procesamiento \"inverso\" a lo definido en la celda anterior. Es decir, remueve el centrado a cero (sumando la media que antes se habia restado) y vuelve al formato RGB (el que espera por ejemplo matplotlib). Este paso es necesario para que no ocurra una interpretación incorrecta de los colores. Además, en la función también se encarga de asegurar que los valores se encuentran entre enteros 0-255 y con el mismo shape que las imagenes de entrada."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "y5LaTrsAu14z"
      },
      "outputs": [],
      "source": [
        "def deprocess_image(x):\n",
        "    x = x.reshape((img_nrows, img_ncols, 3))\n",
        "    # Remove zero-center by mean pixel\n",
        "    x[:, :, 0] += 103.939\n",
        "    x[:, :, 1] += 116.779\n",
        "    x[:, :, 2] += 123.68\n",
        "    # 'BGR'->'RGB'\n",
        "    x = x[:, :, ::-1]\n",
        "    x = np.clip(x, 0, 255).astype('uint8')\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'775px-Neckarfront_Tübingen_Mai_2017.jpg'"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "base_image_path.name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'La_noche_estrellada1.jpg'"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "style_reference_image_path.name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "HYNio09mu4S3"
      },
      "outputs": [],
      "source": [
        "# get tensor representations of our images\n",
        "# K.variable convierte un numpy array en un tensor, para \n",
        "base_image = K.variable(preprocess_image(base_image_path))\n",
        "style_reference_image = K.variable(preprocess_image(style_reference_image_path))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "TensorShape([1, 400, 517, 3])"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "base_image.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UsageError: Line magic function `%skip` not found.\n"
          ]
        }
      ],
      "source": [
        "%skip\n",
        "import tensorflow as tf\n",
        "tmp_img = tf.convert_to_tensor(img_to_array( load_img(base_image_path, target_size=(img_nrows, img_ncols)) ))\n",
        "print(tmp_img.shape)\n",
        "tmp_base_img = K.permute_dimensions(tmp_img, (2, 0, 1))\n",
        "print(tmp_base_img.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "a1Lbw02Uu--o",
        "outputId": "6cc926fa-55af-43fa-fe91-3b68c0910502"
      },
      "outputs": [],
      "source": [
        "combination_image = K.placeholder((1, img_nrows, img_ncols, 3))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "RJEi0YI3Uzrm"
      },
      "source": [
        "Aclaración:\n",
        "\n",
        "La siguiente celda sirve para procesar las tres imagenes (contenido, estilo y salida) en un solo batch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "gGO_jGFfvEbF"
      },
      "outputs": [],
      "source": [
        "# combine the 3 images into a single Keras tensor\n",
        "input_tensor = K.concatenate([base_image,\n",
        "                              style_reference_image,\n",
        "                              combination_image], axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "tdG59VRavHGB",
        "outputId": "a133befb-68d1-4c51-99e6-417c1103f726"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-08-28 13:58:52.998012: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M2 Pro\n",
            "2023-08-28 13:58:52.998034: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
            "2023-08-28 13:58:52.998038: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB\n",
            "2023-08-28 13:58:52.998210: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:303] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
            "2023-08-28 13:58:52.998421: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:269] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
            "2023-08-28 13:58:53.008861: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:375] MLIR V1 optimization pass is not enabled\n",
            "2023-08-28 13:58:53.027751: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
            "2023-08-28 13:58:53.058479: W tensorflow/c/c_api.cc:304] Operation '{name:'block3_conv2/bias/Assign' id:156 op device:{requested: '', assigned: ''} def:{{{node block3_conv2/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](block3_conv2/bias, block3_conv2/bias/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
            "2023-08-28 13:58:53.064992: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model loaded.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-08-28 13:58:53.322140: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
          ]
        }
      ],
      "source": [
        "# build the VGG19 network with our 3 images as input\n",
        "# the model will be loaded with pre-trained ImageNet weights\n",
        "model = vgg19.VGG19(input_tensor=input_tensor,\n",
        "                    weights='imagenet', include_top=False)\n",
        "print('Model loaded.')\n",
        "\n",
        "# get the symbolic outputs of each \"key\" layer (we gave them unique names).\n",
        "outputs_dict = dict([(layer.name, layer.output) for layer in model.layers])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "70-vs_jZkKVc"
      },
      "source": [
        "# 4) En la siguientes celdas:\n",
        "\n",
        "- *¿Qué es la matriz de Gram?¿Para qué se usa?*\n",
        "\n",
        "Se utiliza para capturar la información de estilo de una imagen. Se obtiene realizando la correlación de los features maps para cada capa (layer). Cada elemento de la matriz representa la correlación entre las \"filter responses\" (respuestas al filtro) en 2 posiciones espaciales diferentes. Esta correlación, de alguna forma codifica información sobre como los diferentes features interactuan entre sí y por lo tanto se asume que representan la información de estilo.\n",
        "\n",
        "$$ G^l_{ij} = \\sum{k} F^l_{ik} F^l_{jk} $$\n",
        "\n",
        "- *¿Por qué se permutan las dimensiones de x?*\n",
        "\n",
        "Recordemos que con el preprocesamiento el shape del vector imagen tenia la forma (alto, ancho, canales), con esta permutación se cambia el orden de las dimensiones y queda (canales, ancho, alto) para luego aplicar el batch_flatten que convierte a 2D manteniendo la primer dimensión. Con los vectores que representan la imagen, se puede calcular el producto punto para terminar de calcular la matriz de Gram.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "K1FODPATvJ1k"
      },
      "outputs": [],
      "source": [
        "def gram_matrix(x):\n",
        "    features = K.batch_flatten(K.permute_dimensions(x, (2, 0, 1)))\n",
        "    gram = K.dot(features, K.transpose(features))\n",
        "    return gram"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "vBQkKFY0Rbx-"
      },
      "source": [
        "# 5) Losses:\n",
        "\n",
        "Explicar qué mide cada una de las losses en las siguientes tres celdas.\n",
        "\n",
        "*Rta:*\n",
        "\n",
        "La función style_loss() calcula la Loss de estilo, mediante el cálculo de las matrices de Gram que representan los features maps de estilo de cada imagen, por lo tanto al tomar diferencia como función de Loss que se intentará minimizar, se buscará mantener el estilo contra la imagen de referencia.\n",
        "Responde a la ecuación (4) y (5) del paper \n",
        "$$ E_l = \\frac{1}{4N_l^2 M_l^2} \\sum_{i,j} (G^l_{ij} − A^l_{ij})^2 $$ \n",
        "(E_l, para cada layer)\n",
        "$$ L_{estilo}(a,x) = \\sum_{l=0}^L w_l E_l $$\n",
        "\n",
        "\n",
        "La función content_loss() calcula la Loss para el contenido, la ecuación (1) que es el error cuadrático medio entre las dos representaciones de features\n",
        "$$ L_{contenido} = \\frac{1}{2} \\sum_{i,j} (F^l_{ij} − P^l_{ij})^2 $$\n",
        "\n",
        "\n",
        "Por último total_variation_loss() mide la variación de la imagen de entrada, tomando diferencias absolutas entre valores vecinos, lo pondera por un factor predeterminado (1.25) y lo suma. Esto fomenta reducir el ruido de alta frecuencia en las imágenes generadas, es decir contar con transiciones más suaves."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "1-Gt0ahWvN6q"
      },
      "outputs": [],
      "source": [
        "def style_loss(style, combination):\n",
        "    assert K.ndim(style) == 3\n",
        "    assert K.ndim(combination) == 3\n",
        "    S = gram_matrix(style)\n",
        "    C = gram_matrix(combination)\n",
        "    channels = 3\n",
        "    size = img_nrows * img_ncols\n",
        "    return K.sum(K.square(S - C)) / (4.0 * (channels ** 2) * (size ** 2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "XCqnju5RvQCo"
      },
      "outputs": [],
      "source": [
        "def content_loss(base, combination):\n",
        "    return K.sum(K.square(combination - base))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "udEp5h31vRnY"
      },
      "outputs": [],
      "source": [
        "# Se define el 1.25 como constante (hyperparámetro)\n",
        "def total_variation_loss(x):\n",
        "    assert K.ndim(x) == 4\n",
        "    a = K.square(\n",
        "        x[:, :img_nrows - 1, :img_ncols - 1, :] - x[:, 1:, :img_ncols - 1, :])\n",
        "    b = K.square(\n",
        "        x[:, :img_nrows - 1, :img_ncols - 1, :] - x[:, :img_nrows - 1, 1:, :])\n",
        "    return K.sum(K.pow(a + b, 1.25))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "# RECORDAR: combine the 3 images into a single Keras tensor\n",
        "# input_tensor = K.concatenate([base_image, style_reference_image, combination_image], axis=0)\n",
        "# TENSOR\n",
        "#   0 --> BASE IMG\n",
        "#   1 --> STYLE REFERENCE IMG\n",
        "#   2 --> COMBINATION IMG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "REF_BASE_IMG = 0\n",
        "REF_STYLE_IMG = 1\n",
        "REF_COMB_IMG = 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "-65vcinbvTZ0"
      },
      "outputs": [],
      "source": [
        "# Armamos la loss total\n",
        "loss = K.variable(0.0)\n",
        "\n",
        "layer_features = outputs_dict['block5_conv2']\n",
        "\n",
        "base_image_features = layer_features[REF_BASE_IMG, :, :, :]\n",
        "combination_features = layer_features[REF_COMB_IMG, :, :, :]\n",
        "\n",
        "loss = loss + content_weight * content_loss(base_image_features,combination_features)\n",
        "\n",
        "feature_layers = ['block1_conv1', 'block2_conv1',\n",
        "                  'block3_conv1', 'block4_conv1',\n",
        "                  'block5_conv1']\n",
        "\n",
        "for layer_name in feature_layers:\n",
        "    layer_features = outputs_dict[layer_name]\n",
        "    style_reference_features = layer_features[REF_STYLE_IMG, :, :, :] \n",
        "    combination_features = layer_features[REF_COMB_IMG, :, :, :]\n",
        "    \n",
        "    sl = style_loss(style_reference_features, combination_features)\n",
        "    loss = loss + (style_weight / len(feature_layers)) * sl\n",
        "\n",
        "loss = loss + total_variation_weight * total_variation_loss(combination_image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "id": "pbz4n1OhvV2K",
        "outputId": "c2b208c6-7ddd-4a40-eeda-525f0809b963"
      },
      "outputs": [],
      "source": [
        "grads = K.gradients(loss, combination_image)\n",
        "\n",
        "outputs = [loss]\n",
        "if isinstance(grads, (list, tuple)):\n",
        "    outputs += grads\n",
        "else:\n",
        "    outputs.append(grads)\n",
        "\n",
        "f_outputs = K.function([combination_image], outputs)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "1JbydbOaVcvU"
      },
      "source": [
        "# 6) Explique el propósito de las siguientes tres celdas. ¿Qué hace la función fmin_l_bfgs_b? ¿En qué se diferencia con la implementación del paper? ¿Se puede utilizar alguna alternativa?\n",
        "\n",
        "*Respuesta:*\n",
        "\n",
        "*fmin_l_bfgs_b()* es una función de la biblioteca SciPy. Se trata de una implementación de la optimización de Broyden-Fletcher-Goldfarb-Shanno (L-BFGS-B) en particular, de un algoritmo de optimización diseñado para memoria limitada (ver paper en la referencia). Es una técnica de optimización numérica que se utiliza para encontrar los mínimos (óptimos) de una función objetivo en función de varias variables, sujetas a restricciones de límites en esas variables.\n",
        "\n",
        "Ref: https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.fmin_l_bfgs_b.html \n",
        "\n",
        "El algoritmo L-BFGS-B es adecuado para problemas de optimización sin restricciones o con restricciones con límites (es decir, cuando las variables deben mantenerse dentro de ciertos rangos). A diferencia de algunos otros algoritmos de optimización, L-BFGS-B no requiere cálculos de derivadas y es eficiente en problemas donde el número de variables es grande.\n",
        "\n",
        "En las siguiente celda se define una clase Evaluator con tres métodos. Uno default de incialización, uno de loss y otro de gradientes. El primero ejecuta la función eval_loss_and_grads(x) que retorna loss_value y grad_value. El método grads(), realiza una copia. Esto se utiliza en el punto 7)\n",
        "\n",
        "En el paper utilizan el método de Gradientes Descendientes para la minimización, que ajusta los parámetros en la dirección opuesta al gradiente de la función objetivo para minimizarla. Es el de los métodos de minimización más simple y es el que se suele utilizar habitualmente. Tiene como hyperparámetro el Learning Rate y utiliza derivadas. L-BFGS-B es una técnica más avanzada que a menudo converge más rápido y es más robusta en problemas de optimización convexa.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "zVE1_qemvZeN"
      },
      "outputs": [],
      "source": [
        "def eval_loss_and_grads(x):\n",
        "    # Reshape the input image to match the expected input shape for the model\n",
        "    x = x.reshape((1, img_nrows, img_ncols, 3))\n",
        "    # Compute the loss and gradients for the input image\n",
        "    outs = f_outputs([x])\n",
        "    # Extract the loss value from the computed outputs\n",
        "    loss_value = outs[0]\n",
        "    # If there is only one gradient value, flatten it and convert to float64\n",
        "    if len(outs[1:]) == 1:\n",
        "        grad_values = outs[1].flatten().astype('float64')\n",
        "    # If there are multiple gradient values, convert them to a flat numpy array of float64\n",
        "    else:\n",
        "        grad_values = np.array(outs[1:]).flatten().astype('float64')\n",
        "    # Return the computed loss and gradient values\n",
        "    return loss_value, grad_values\n",
        "\n",
        "# this Evaluator class makes it possible\n",
        "# to compute loss and gradients in one pass\n",
        "# while retrieving them via two separate functions,\n",
        "# \"loss\" and \"grads\". This is done because scipy.optimize\n",
        "# requires separate functions for loss and gradients,\n",
        "# but computing them separately would be inefficient."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "Qbl9roIgvdb1"
      },
      "outputs": [],
      "source": [
        "class Evaluator(object):\n",
        "\n",
        "    def __init__(self):\n",
        "        self.loss_value = None\n",
        "        self.grads_values = None\n",
        "\n",
        "    def loss(self, x):\n",
        "        assert self.loss_value is None\n",
        "        loss_value, grad_values = eval_loss_and_grads(x)\n",
        "        self.loss_value = loss_value\n",
        "        self.grad_values = grad_values\n",
        "        return self.loss_value\n",
        "\n",
        "    def grads(self, x):\n",
        "        assert self.loss_value is not None\n",
        "        grad_values = np.copy(self.grad_values)\n",
        "        self.loss_value = None\n",
        "        self.grad_values = None\n",
        "        return grad_values"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Sb0yOEl-WOE6"
      },
      "source": [
        "# 7) Ejecute la siguiente celda y observe las imágenes de salida en cada iteración."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "!mkdir -p content/output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Content: 775px-Neckarfront_Tübingen_Mai_2017\n",
            "Style: La_noche_estrellada1\n",
            "total_variation_weight: 0.1\n",
            "style_weight: 10\n",
            "content_weight: 1\n",
            "Iterations: 100\n"
          ]
        }
      ],
      "source": [
        "print(\"Content:\", base_image_path.name.split(\".\")[0])\n",
        "print(\"Style:\", style_reference_image_path.name.split(\".\")[0])\n",
        "print(\"total_variation_weight:\", total_variation_weight)\n",
        "print(\"style_weight:\", style_weight)\n",
        "print(\"content_weight:\", content_weight)\n",
        "print(\"Iterations:\", iterations)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "BASEIMG = base_image_path.name.upper().split(\".\")[0]\n",
        "STYLEIMG = style_reference_image_path.name.upper().split(\".\")[0]\n",
        "TOTALVARIATIONW = str(total_variation_weight)\n",
        "STYLEW = str(style_weight)\n",
        "CONTENTW = str(content_weight)\n",
        "IT_NUMBER = str(1)\n",
        "# print(f'output_{BASEIMG}_{STYLEIMG}_{TOTALVARIATIONW}_{STYLEW}_{CONTENTW}_at_iteration_{IT_NUMBER}.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "n31YBwCVvhAI",
        "outputId": "4c1bf03c-9d66-48ea-93f2-4489fc20beaa"
      },
      "outputs": [],
      "source": [
        "evaluator = Evaluator() # \n",
        "\n",
        "# run scipy-based optimization (L-BFGS) over the pixels of the generated image\n",
        "# so as to minimize the neural style loss\n",
        "x = preprocess_image(base_image_path)\n",
        "\n",
        "for i in range(iterations):\n",
        "    print('Start of iteration', i)\n",
        "    start_time = time.time()\n",
        "    x, min_val, info = fmin_l_bfgs_b(evaluator.loss, x.flatten(),\n",
        "                                     fprime=evaluator.grads, maxfun=20)\n",
        "    print('Current loss value:', min_val)\n",
        "    # save current generated image\n",
        "    img = deprocess_image(x.copy())\n",
        "    # fname = result_prefix / ('output_at_iteration_%d.png' % i)\n",
        "    fname = result_prefix / (f'output_{BASEIMG}_{STYLEIMG}_{TOTALVARIATIONW}_{STYLEW}_{CONTENTW}_at_iteration_{i}.png')\n",
        "    save_img(fname, img)\n",
        "    end_time = time.time()\n",
        "    print('Image saved as', fname)\n",
        "    print('Iteration %d completed in %ds' % (i, end_time - start_time))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "SkiJtofbWWy1"
      },
      "source": [
        "# 8) Generar imágenes para distintas combinaciones de pesos de las losses. Explicar las diferencias. (Adjuntar las imágenes generadas como archivos separados.)\n",
        "\n",
        "*Respuesta:*\n",
        "En la siguientes celda se modifican los hiperparámetros con distintas combinaciones de pesos para obtener diferentes resultados."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Referencia output punto 7 (default)\n",
        "\n",
        "<center>\n",
        "\n",
        "| Content | Style |\n",
        "| --- | --- |\n",
        "| <img src='./content/775px-Neckarfront_Tübingen_Mai_2017.jpg'> | <img src='./content/La_noche_estrellada1.jpg'> |\n",
        "\n",
        "\n",
        "| total_variation_weight | style_weight | content_weight | interations |\n",
        "| --- | --- | --- | --- |\n",
        "| 0.01 | 10 | 1 | 100 |\n",
        "\n",
        "\n",
        "\n",
        "<img src='./resultados/PUNTO-7/output_at_iteration_99.png'>\n",
        "\n",
        "</center>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Combinación 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Más peso para el estilo y menor variation weight\n",
        "total_variation_weight = 0.01\n",
        "style_weight = 50\n",
        "content_weight = 1\n",
        "\n",
        "iterations = 100"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<center>\n",
        "\n",
        "| total_variation_weight | style_weight | content_weight | interations |\n",
        "| --- | --- | --- | --- |\n",
        "| 0.01 | 50 | 1 | 100 |\n",
        "\n",
        "<img src='./resultados/PUNTO-8/output_Neckarfront_NOCHE-ESTRELLADA_0.01_50_1_at_iteration_99.png'>\n",
        "\n",
        "</center>\n",
        "\n",
        "*Si bien a primera vista el resultado se ve parecido al output del punto 7, al bajar el variation weight se observa que se aprecian mejor los detalles, es decir hay menos ruido de alta frecuencia. La evaluación del estilo es subjetiva, pero a pesar de haber subido el peso x5 no se notan grandes diferencias para esta imagen. De todas formas, como se nota por comparación en el punto 9, depende también de las característictas de la imagen que se utilice como referencia para el estilo*"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Combinación 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Genero contenido más parecido al original cambiando los pesos\n",
        "# Combinación 2\n",
        "total_variation_weight = 0.01\n",
        "style_weight = 1\n",
        "content_weight = 1000\n",
        "\n",
        "iterations = 100"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<center>\n",
        "\n",
        "| total_variation_weight | style_weight | content_weight | interations |\n",
        "| --- | --- | --- | --- |\n",
        "| 0.01 | 1 | 1000 | 100 |\n",
        "\n",
        "<img src='./resultados/PUNTO-8/output_Neckarfront_NOCHE-ESTRELLADA_0.01_1_1000_at_iteration_99.png'>\n",
        "\n",
        "*Al aumentar el peso del contenido y bajar el total variation weight se observa, como era de esperar, un leve cambio de estilo, manteniendo el foto realismo de la imagen original*"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Combinación 3"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<center>\n",
        "\n",
        "| total_variation_weight | style_weight | content_weight | interations |\n",
        "| --- | --- | --- | --- |\n",
        "| 1 | 10000 | 0.01 | 50 |\n",
        "\n",
        "<img src='./resultados/PUNTO-8/output_775PX-NECKARFRONT_TÜBINGEN_MAI_2017_LA_NOCHE_ESTRELLADA1_1_10000_0.01_at_iteration_50.png'>\n",
        "\n",
        "*En este caso, donde se aumenta mucho el peso del estilo y se reduce el del contenido, se nota como el resultado, si bien conserva las formas macro del contenido original, se empieza a parecer cada vez más a la imagen del estilo. Sin embargo, no se aprecia demasiada diferencia en el resultado con la Combinación 2, dónde también se aumenta el peso del estilo, pero no tanto como en este caso* "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "# 9) Cambiar las imágenes de contenido y estilo por unas elegidas por usted. Adjuntar el resultado.\n",
        "\n",
        "Respuesta: Se configuran diferentes imagenes para contenido y estilo, y se definen diferentes hiperparámetros."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Base\n",
        "base_image_path = Path.cwd() / Path(\"content-propio/Toto_small.jpg\")\n",
        "# base_image_path = Path.cwd() / Path(\"content-propio/achiras_pelota_small.jpg\")\n",
        "\n",
        "# Style\n",
        "style_reference_image_path = Path.cwd() / Path(\"content/La_noche_estrellada1.jpg\")\n",
        "# style_reference_image_path = Path.cwd() / Path(\"content-propio/nieve_small.jpg\")\n",
        "# style_reference_image_path = Path.cwd() / Path(\"content-propio/cubism.png\")\n",
        "# style_reference_image_path = Path.cwd() / Path(\"content-propio/kandinsky_small.jpg\")\n",
        "\n",
        "result_prefix = Path.cwd() / Path(\"content-propio/output\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(base_image_path.name)\n",
        "print(style_reference_image_path.name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "! mkdir -p content-propio/output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Definimos el tamaño de las imágenes a utilizar (se conserva tamaño original)\n",
        "width, height = load_img(base_image_path).size\n",
        "img_nrows = height\n",
        "img_ncols = width\n",
        "print(img_nrows, img_ncols)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Hiperparámetros del modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "total_variation_weight = 0.01\n",
        "# total_variation_weight = 0.5\n",
        "# total_variation_weight = 0.1\n",
        "\n",
        "# style_weight = 1000\n",
        "style_weight = 5\n",
        "# style_weight = 50\n",
        "# style_weight = 10\n",
        "\n",
        "content_weight = 1\n",
        "\n",
        "iterations = 100\n",
        "# iterations = 300\n",
        "# iterations = 3\n",
        "# iterations = 10"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<center>\n",
        "\n",
        "| Content | Style |\n",
        "| --- | --- |\n",
        "| <img src='./content-propio/Toto_small.jpg'> | <img src='./content/La_noche_estrellada1.jpg'> |\n",
        "\n",
        "\n",
        "| total_variation_weight | style_weight | content_weight | interations |\n",
        "| --- | --- | --- | --- |\n",
        "| 0.01 | 10 | 1 | 100 |\n",
        "\n",
        "\n",
        "<img src='./resultados/PUNTO-9/output_TOTO_NOCHE-ESTRELLADA_0.1_10_1_at_iteration_99.png'>\n",
        "\n",
        "</center>\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<center>\n",
        "\n",
        "| Content | Style |\n",
        "| --- | --- |\n",
        "| <img src='./content-propio/Toto_small.jpg'> | <img src='./content-propio/kandinsky_small.jpg'> |\n",
        "\n",
        "\n",
        "| total_variation_weight | style_weight | content_weight | interations |\n",
        "| --- | --- | --- | --- |\n",
        "| 0.01 | 10 | 1 | 40 |\n",
        "\n",
        "\n",
        "<img src='./resultados/PUNTO-9/output_TOTO_Kandinsky_0.01_10_1_at_iteration_40.png'>\n",
        "\n",
        "</center>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "total_variation_weight, style_weight, content_weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "style_weight"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<center>\n",
        "\n",
        "| Content | Style |\n",
        "| --- | --- |\n",
        "| <img src='./content-propio/Toto_small.jpg'> | <img src='./content-propio/cubism.png'> |\n",
        "\n",
        "\n",
        "| total_variation_weight | style_weight | content_weight | interations |\n",
        "| --- | --- | --- | --- |\n",
        "| 0.5 | 10 | 1 | 100 |\n",
        "\n",
        "\n",
        "<img src='./resultados/PUNTO-9/output_TOTO_Cubism_0.5_10_1_at_iteration_99.png'>\n",
        "\n",
        "</center>\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<center>\n",
        "\n",
        "| Content | Style |\n",
        "| --- | --- |\n",
        "| <img src='./content-propio/achiras_pelota_small.jpg'> | <img src='./content/La_noche_estrellada1.jpg'> |\n",
        "\n",
        "\n",
        "| total_variation_weight | style_weight | content_weight | interations |\n",
        "| --- | --- | --- | --- |\n",
        "| 0.01 | 5 | 1 | 100 |\n",
        "\n",
        "\n",
        "<img src='./resultados/PUNTO-9/output_PELOTA_NOCHE-ESTRELLADA_0.01_5_1_iteration_99.png'>\n",
        "\n",
        "</center>\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<center>\n",
        "\n",
        "| Content | Style |\n",
        "| --- | --- |\n",
        "| <img src='./content-propio/achiras_pelota_small.jpg'> | <img src='./content-propio/cubism.png'> |\n",
        "\n",
        "\n",
        "| total_variation_weight | style_weight | content_weight | interations |\n",
        "| --- | --- | --- | --- |\n",
        "| 0.5 | 5 | 1 | 100 |\n",
        "\n",
        "\n",
        "<img src='./resultados/PUNTO-9/output_PELOTA_Cubism_0.5_5_1_iteration_99.png'>\n",
        "\n",
        "</center>\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Trabajo Final CNN - Style Transfer.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
